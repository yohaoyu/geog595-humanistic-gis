{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "061_wordembedments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_LufHE3Ryt3e"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
        "from sklearn.manifold import TSNE                   # final reduction\n",
        "import numpy as np                                  # array handling\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Create data on to Google Drive\n",
        "from google.colab import drive\n",
        "# Mount your Drive to the Colab VM.\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6CeZ_cUy-dq",
        "outputId": "ca10e437-029e-48f4-b678-2a119062dffe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load(\"/gdrive/MyDrive/geog595/gay-seattle.w2v\")"
      ],
      "metadata": {
        "id": "My100bpsy3cP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def reduce_dimensions(model):\n",
        "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
        "\n",
        "    vectors = [] # positions in vector space\n",
        "    labels = [] # keep track of words to label our data again later\n",
        "    for word in model.wv.vocab:\n",
        "        vectors.append(model.wv[word])\n",
        "        labels.append(word)\n",
        "\n",
        "    # convert both lists into numpy vectors for reduction\n",
        "    vectors = np.asarray(vectors)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    # reduce using t-SNE\n",
        "    vectors = np.asarray(vectors)\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    x_vals = [v[0] for v in vectors]\n",
        "    y_vals = [v[1] for v in vectors]\n",
        "    return x_vals, y_vals, labels\n",
        "\n",
        "\n",
        "x_vals, y_vals, labels = reduce_dimensions(model)\n",
        "\n",
        "\n",
        "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import random\n",
        "\n",
        "    random.seed(0)\n",
        "\n",
        "    plt.figure(figsize=(64, 64))\n",
        "    plt.scatter(x_vals, y_vals)\n",
        "\n",
        "    #\n",
        "    # Label randomly subsampled 25 data points\n",
        "    #\n",
        "    indices = list(range(len(labels)))\n",
        "    selected_indices = random.sample(indices, 100)\n",
        "    for i in selected_indices:\n",
        "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_with_matplotlib(x_vals, y_vals, labels)\n",
        "print(\"finished\")\n",
        "\n"
      ],
      "metadata": {
        "id": "q3tDiEZazPP6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}